# ëª©ì  
ì´ ì½”ë“œëŠ” [Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ë°ì´í„° ìƒì„±, í•™ìŠµ, í‰ê°€ê¹Œì§€ ë°‘ë°”ë‹¥ë¶€í„° Instruction Tuningì„ ì‹¤ìŠµí•´ë³´ëŠ” ì½”ë“œì…ë‹ˆë‹¤.  
ì°¸ì¡° ë…¼ë¬¸ê³¼ ê¹ƒí—ˆë¸Œë“¤ì€ ë§í¬ê°€ ê±¸ë ¤ìˆìœ¼ë‹ˆ, ë˜ë„ë¡ ì›ë³¸ ë¬¸ì„œë¥¼ ê°™ì´ ë³´ë©´ì„œ í•™ìŠµí•´ë³´ë©´ í° ë„ì›€ì´ ë  ê²ƒ ê°™ìŠµë‹ˆë‹¤. 

# ëª©ì°¨
[ê°œìš”](#ê°œìš”)  
[í›ˆë ¨ ìŠ¤í™](#í›ˆë ¨-ìŠ¤í™)  
[ì½”ë“œ íŠ¸ë¦¬](#ì½”ë“œ-íŠ¸ë¦¬)  
[ì°¸ì¡° ë¬¸ì„œ](#ì°¸ì¡°-ë¬¸ì„œ)  
[Colab ì‹¤í–‰ ê°€ì´ë“œ](#Colab-ì‹¤í–‰-ê°€ì´ë“œ)  

# ê°œìš”
ì´ ì˜ˆì œ ì½”ë“œ í¬ê²Œ 3ê°€ì§€ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  
1. OpenAIì˜ GPT APIë¥¼ í†µí•´ [ë°ì´í„°ë¥¼ ìƒì„±](data/instruction.jsonl)í•©ë‹ˆë‹¤. 
2. ìƒì„±í•œ ë°ì´í„°ë¡œ [gemma-2b-it](https://huggingface.co/google/gemma-2b-it) ëª¨ë¸ì„ Fine-Tuningí•©ë‹ˆë‹¤.
3. í•™ìŠµí•œ ëª¨ë¸ì„ [LLMìœ¼ë¡œ í‰ê°€](https://arxiv.org/pdf/2306.05685)í•©ë‹ˆë‹¤.

ì½”ë“œì˜ êµ¬ì„±ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.  
+ `utils.py`, `similarity.py`, `prompts.py`ë¥¼ ì»¤ìŠ¤í…€ ëª¨ë“ˆë¡œ `import`í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.
+ ë°ì´í„° ìƒì„±ê³¼ í•™ìŠµì€ ì£¼í”¼í„° ë…¸íŠ¸ë¶ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.
![process](assets/process_resize.png)  

[preprocess.ipynb](preprocess.ipynb)  
ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ëŠ” ê³¼ì •ì„ ë‹´ì•˜ìŠµë‹ˆë‹¤. ë°ì´í„° ìƒì„±ì€ gpt-4-turboì™€ gpt-4o APIë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.  
(ë°ì´í„°ë¥¼ ê°œì„ ì‹œí‚¤ëŠ” ë§‰ë°”ì§€ì— gpt-4oê°€ ì¶œì‹œë˜ì–´ ì›ê°€ ì ˆê°ì— í° ë„ì›€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤ ğŸ˜†)

[train.ipynb](train.ipynb)  
`Dataset` ìƒì„± ë“± ë°ì´í„° ì¤€ë¹„ê³¼ì •ê³¼ LoRAí•™ìŠµë“± Trainingì½”ë“œê°€ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤.

[evaluation.ipynb](evaluation.ipynb)  
LLMìœ¼ë¡œ ë¶€í„° Evaluationì„ ë°›ëŠ” ì½”ë“œê°€ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤.

# ì˜ˆì œ ëª¨ë¸
ì˜ˆì œ ëª¨ë¸ì€ [https://huggingface.co/aiqwe/gemma-2b-it-example-v1](https://huggingface.co/aiqwe/gemma-2b-it-example-v1)ë¥¼ ì°¸ì¡°í•´ì£¼ì„¸ìš”.

# í›ˆë ¨ ìŠ¤í™
í•™ìŠµì€ ì‰½ê²Œ ì‹¤í—˜í•´ ë³¼ ìˆ˜ ìˆë„ë¡ [Google Colab](https://colab.google/)ì„ ì‚¬ìš©í–ˆìœ¼ë©°, ì˜ˆì œ ëª¨ë¸ì˜ í›ˆë ¨ì‹œ ìŠ¤í™ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

| êµ¬ë¶„                          | ë‚´ìš©               |
|-----------------------------|------------------|
| í™˜ê²½                          | Google Colab     |
| GPU                         | L4(22.5GB)       |
| ì‚¬ìš© VRAM                     | ì•½ 13.8GB         |
| dtype                       | bfloat16         |
| Attention                   | flash attention2 |
| Tuning                      | Lora(r=4, alpha=32) |
| Learning Rate               | 1e-4             |
| LRScheduler                 | Cosine           |
| Optimizer                   | adamw_torch_fused |
| batch_size                  | 4                |
| gradient_accumulation_steps | 2                |

Colabì—ì„œ A100ì€ ìì£¼ ì—°ê²°ì´ ëŠì–´ì§€ê¸° ë•Œë¬¸ì— ë³´ë‹¤ ì•ˆì •ì ì¸ L4 GPUë¡œ í›ˆë ¨í•˜ì˜€ìŠµë‹ˆë‹¤.

# Colab Guide
Colabì—ì„œ ì‹¤í–‰í•˜ê¸°ìœ„í•´ [colab_guide.md](colab_guide.md)ë¥¼ ì°¸ì¡°í•´ì£¼ì„¸ìš”.

# References
+ [Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca)
+ [Prompt Engineering(deeplearning.ai)](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers)
+ [google/gemma-2b-it](https://huggingface.co/google/gemma-2b-it)
+ [Fine-Tuning Gemma Models in Hugging Face](https://huggingface.co/blog/gemma-peft)
+ [Openai API - Python](https://github.com/openai/openai-python)
+ [Flash Attention](https://github.com/Dao-AILab/flash-attention)
+ [ë„¤ì´ë²„ API ê°€ì´ë“œ](https://developers.naver.com/docs/common/openapiguide/)

