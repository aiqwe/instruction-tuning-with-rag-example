{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d015e7-f608-4f2c-a580-e476e4d23455",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-27T14:24:44.399720Z",
     "iopub.status.busy": "2024-04-27T14:24:44.399074Z",
     "iopub.status.idle": "2024-04-27T14:24:44.688783Z",
     "shell.execute_reply": "2024-04-27T14:24:44.688485Z",
     "shell.execute_reply.started": "2024-04-27T14:24:44.399656Z"
    },
    "tags": []
   },
   "source": [
    "### 데이터셋 준비 하기\n",
    "Instruction Fine Tuning을 위해 데이터셋을 준비합니다.  \n",
    "데이터셋은 아래의 순서로 준비합니다.\n",
    "---\n",
    "\n",
    "1. 도메인 정하기  \n",
    "부동산에 대해 잘 대답할 수 있는 챗봇을 타겟으로 설정합니다.  \n",
    "\n",
    "2. 부동산에 관련된 키워드를 생각해보기  \n",
    "책, 뉴스, 부동산 사이트에서 키워드를 수집합니다. 사람들이 궁금해할만한 키워드를 대상으로 합니다. (예: 전세 계약, 신혼부부 특별공급, 토지거래허가구역...)  \n",
    "\n",
    "3. 부동산 키워드를 통해 사람들이 찾아볼만한 질문리스트 만들어보기(`query.jsonl`)  \n",
    "2번에서 수집한 키워드를 기반으로, 사람들이 궁금해할만한 질문리스트를 ChatGPT를 활용해 만들어봅니다. 충분한 데이터셋 확보할 만큼의 질문리스트를 생성합니다.\n",
    "\n",
    "4. 질문리스트로 네이버에 검색하여 인기 글 데이터 수집하기(`search_data.json`)  \n",
    "3번에서 수집한 질문리스트를 Selenium 라이브러리를 활용하여 네이버에 검색합니다. 검색 결과중 인기글의 텍스트 데이터를 추출합니다.\n",
    "\n",
    "5. encoder 모델을 활용하여 데이터를 유사도 기준으로 정렬하기(`search_data.json`)  \n",
    "4번에서 수집한 인기글 텍스트 데이터가 질문리스트와 얼마나 유사한지 계산합니다.\n",
    "질문리스트와 가장 유사한 인기글 텍스트를 상위 순위로 정렬합니다.\n",
    "\n",
    "6. Instuction 데이터셋 만들기(`instruction.jsonl`)  \n",
    "질문리스트 + 정렬한 인기글을 합쳐서 ChatGPT에 Instruction 데이터를 만들어달라고 요청합니다. 이 Instruction 데이터는 Fine Tuning에 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236cc32b-567d-4444-97cb-b3eff129879d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T09:00:16.148751Z",
     "iopub.status.busy": "2024-04-30T09:00:16.148614Z",
     "iopub.status.idle": "2024-04-30T09:00:16.150524Z",
     "shell.execute_reply": "2024-04-30T09:00:16.150228Z",
     "shell.execute_reply.started": "2024-04-30T09:00:16.148738Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --quiet\\\n",
    "selenium\\\n",
    "openai\\\n",
    "colorama\\\n",
    "datasets\\\n",
    "accelerate==0.27.2\\\n",
    "flash-attn\\\n",
    "peft\\\n",
    "trl\\\n",
    "transformers\\\n",
    "python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "771138c9-f9e6-49ed-a04e-21486d54cb56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:26:22.149974Z",
     "iopub.status.busy": "2024-05-01T03:26:22.149838Z",
     "iopub.status.idle": "2024-05-01T03:26:25.545810Z",
     "shell.execute_reply": "2024-05-01T03:26:25.545518Z",
     "shell.execute_reply.started": "2024-05-01T03:26:22.149962Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "import prompts\n",
    "import json\n",
    "import similarity\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2efb55f-3c57-4e7e-89e3-96fcab92db7d",
   "metadata": {},
   "source": [
    "### 2. 부동산에 관련된 키워드를 생각해보기\n",
    "부동산에 관련된 키워드를 수집하여 저장합니다.  \n",
    "예시 데이터는 `seed_words.txt` 파일로 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8703faac-3a56-4259-b2f8-003c63485699",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:26:25.546561Z",
     "iopub.status.busy": "2024-05-01T03:26:25.546416Z",
     "iopub.status.idle": "2024-05-01T03:26:25.548201Z",
     "shell.execute_reply": "2024-05-01T03:26:25.547987Z",
     "shell.execute_reply.started": "2024-05-01T03:26:25.546550Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./data/seed_words.txt\", \"r\") as f:\n",
    "    seed_words = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b731610-6b30-4eb4-ae3a-5faa7175b005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:26:27.247298Z",
     "iopub.status.busy": "2024-05-01T03:26:27.246594Z",
     "iopub.status.idle": "2024-05-01T03:26:27.256986Z",
     "shell.execute_reply": "2024-05-01T03:26:27.256257Z",
     "shell.execute_reply.started": "2024-05-01T03:26:27.247245Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['전세 계약\\n', '임대차 계약\\n', '전세 사기\\n', '임대차 분쟁\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_words[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cd9daee-9abf-49ca-a418-1515ef78aab3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:26:27.653422Z",
     "iopub.status.busy": "2024-05-01T03:26:27.652870Z",
     "iopub.status.idle": "2024-05-01T03:26:27.660195Z",
     "shell.execute_reply": "2024-05-01T03:26:27.658252Z",
     "shell.execute_reply.started": "2024-05-01T03:26:27.653359Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Element마다 있는 \\n 제거, '전세 계약\\n' -> '전세 계약'\n",
    "seed_words = list(map(lambda x: x.strip(\"\\n\"), seed_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4a7994b-fe60-4f7a-9446-22ee51936085",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:26:27.944044Z",
     "iopub.status.busy": "2024-05-01T03:26:27.943282Z",
     "iopub.status.idle": "2024-05-01T03:26:27.952531Z",
     "shell.execute_reply": "2024-05-01T03:26:27.951627Z",
     "shell.execute_reply.started": "2024-05-01T03:26:27.943987Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['전세 계약', '임대차 계약', '전세 사기', '임대차 분쟁']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_words[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c539ba2e-355f-4482-a1d7-b8a315a43c2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-27T14:46:47.170359Z",
     "iopub.status.busy": "2024-04-27T14:46:47.169552Z",
     "iopub.status.idle": "2024-04-27T14:46:47.181132Z",
     "shell.execute_reply": "2024-04-27T14:46:47.178484Z",
     "shell.execute_reply.started": "2024-04-27T14:46:47.170307Z"
    },
    "tags": []
   },
   "source": [
    "### 3. 부동산 키워드를 통해 사람들이 찾아볼만한 질문리스트 만들어보기\n",
    "`format` 메서드를 적용할 수 있게 프롬프트를 미리 작성합니다.  \n",
    "미리 작성된 프롬프트에 `seed_words`를 `format` 적용하여 프롬프트를 완성시킵니다.  \n",
    "예시 데이터는 `query.jsonl` 파일로 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f06a5e79-9697-4ff9-ac38-6b23d298a483",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:26:29.199341Z",
     "iopub.status.busy": "2024-05-01T03:26:29.198421Z",
     "iopub.status.idle": "2024-05-01T03:26:29.205396Z",
     "shell.execute_reply": "2024-05-01T03:26:29.204327Z",
     "shell.execute_reply.started": "2024-05-01T03:26:29.199298Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주어진 seed_word에 대해 궁금해할 질문을 10개를 생성하세요.\n",
      "만들어낸 질문은 JSON형식을 따라야 합니다.\n",
      "Indentation은 없도록 출력하세요.\n",
      "아래 양식으로 출력하세요:\n",
      "{{\"seed_word\": \"{seed_word}\", \"answer\": [\"1번째 질문\", \"2번째 질문\"... , \"10번째 질문\"]}}\n"
     ]
    }
   ],
   "source": [
    "print(prompts.SEED_WORD_PROMPT_PREFIX + prompts.SEED_WORD_PROMPT_CONTENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18924823-18df-4d08-8b9a-34184d3f8153",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:26:29.372922Z",
     "iopub.status.busy": "2024-05-01T03:26:29.372317Z",
     "iopub.status.idle": "2024-05-01T03:26:29.376769Z",
     "shell.execute_reply": "2024-05-01T03:26:29.376223Z",
     "shell.execute_reply.started": "2024-05-01T03:26:29.372869Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주어진 seed_word에 대해 궁금해할 질문을 10개를 생성하세요.\n",
      "만들어낸 질문은 JSON형식을 따라야 합니다.\n",
      "Indentation은 없도록 출력하세요.\n",
      "아래 양식으로 출력하세요:\n",
      "{\"seed_word\": \"전세 계약\", \"answer\": [\"1번째 질문\", \"2번째 질문\"... , \"10번째 질문\"]}\n"
     ]
    }
   ],
   "source": [
    "print(prompts.SEED_WORD_PROMPT_PREFIX + prompts.SEED_WORD_PROMPT_CONTENT.format(seed_word=seed_words[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea0cf546-2d03-4c4e-b433-e02fb9bfed34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:26:30.298802Z",
     "iopub.status.busy": "2024-05-01T03:26:30.297922Z",
     "iopub.status.idle": "2024-05-01T03:26:30.306194Z",
     "shell.execute_reply": "2024-05-01T03:26:30.305135Z",
     "shell.execute_reply.started": "2024-05-01T03:26:30.298732Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 모델에게 Prefix 토큰을 중복해서 전달할 필요가 없으므로, Prefix 토큰은 1번만 사용하고 Content을 반복해서 프롬프트를 생성\n",
    "seed_word_prefix = prompts.SEED_WORD_PROMPT_PREFIX\n",
    "seed_word_content = [prompts.SEED_WORD_PROMPT_CONTENT.format(seed_word=s) for s in seed_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d94a38a-2f41-47ae-84a0-fec8a8cbe016",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:26:30.519853Z",
     "iopub.status.busy": "2024-05-01T03:26:30.519257Z",
     "iopub.status.idle": "2024-05-01T03:26:30.524651Z",
     "shell.execute_reply": "2024-05-01T03:26:30.523762Z",
     "shell.execute_reply.started": "2024-05-01T03:26:30.519821Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 모델에게 Prefix 토큰을 중복해서 전달할 필요가 없으므로, Prefix 토큰은 1번만 사용하고 Content을 반복해서 프롬프트를 생성\n",
    "# 1개의 Prefix 마다 10개의 Content를 추가한다\n",
    "seed_word_prompts = []\n",
    "total_prompts = len(seed_words) // 10\n",
    "for idx in range(1, total_prompts+2):\n",
    "    start_index = (idx -1) * 10\n",
    "    end_index = idx * 10\n",
    "    seed_word_prompt = seed_word_prefix + \"\\n\".join(seed_word_content[start_index:end_index])\n",
    "    seed_word_prompts.append(seed_word_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45756685-409d-44e9-9833-c90d5d5a8ae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:26:30.706612Z",
     "iopub.status.busy": "2024-05-01T03:26:30.706057Z",
     "iopub.status.idle": "2024-05-01T03:26:30.711667Z",
     "shell.execute_reply": "2024-05-01T03:26:30.710402Z",
     "shell.execute_reply.started": "2024-05-01T03:26:30.706570Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주어진 seed_word에 대해 궁금해할 질문을 10개를 생성하세요.\n",
      "만들어낸 질문은 JSON형식을 따라야 합니다.\n",
      "Indentation은 없도록 출력하세요.\n",
      "아래 양식으로 출력하세요:\n",
      "{\"seed_word\": \"장기보유 특별 공제\", \"answer\": [\"1번째 질문\", \"2번째 질문\"... , \"10번째 질문\"]}\n",
      "{\"seed_word\": \"주택임대사업자\", \"answer\": [\"1번째 질문\", \"2번째 질문\"... , \"10번째 질문\"]}\n",
      "{\"seed_word\": \"종부세 중과세\", \"answer\": [\"1번째 질문\", \"2번째 질문\"... , \"10번째 질문\"]}\n",
      "{\"seed_word\": \"보금자리론\", \"answer\": [\"1번째 질문\", \"2번째 질문\"... , \"10번째 질문\"]}\n",
      "{\"seed_word\": \"디딤돌대출\", \"answer\": [\"1번째 질문\", \"2번째 질문\"... , \"10번째 질문\"]}\n",
      "{\"seed_word\": \"정책모기지\", \"answer\": [\"1번째 질문\", \"2번째 질문\"... , \"10번째 질문\"]}\n"
     ]
    }
   ],
   "source": [
    "print(seed_word_prompts[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83112114-910f-42e6-96a4-96b4ef6cca19",
   "metadata": {},
   "source": [
    "### 4. 질문리스트로 네이버에 검색하여 인기 글 데이터 수집하기\n",
    "3번에서 생성한 질문리스트를 selenium 라이브러리를 통해 네이버로 검색합니다.  \n",
    "검색 결과의 인기글의 텍스트 정보를 저장합니다.  \n",
    "예시 데이터는 `search.jsonl`로 제공합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae2f00a6-9463-4689-adc3-23edb4fcbef4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:26:32.101454Z",
     "iopub.status.busy": "2024-05-01T03:26:32.100579Z",
     "iopub.status.idle": "2024-05-01T03:26:32.108504Z",
     "shell.execute_reply": "2024-05-01T03:26:32.107661Z",
     "shell.execute_reply.started": "2024-05-01T03:26:32.101369Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_data = utils.jload(\"./data/query.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae8c5144-b151-4e2a-b9f4-c4a12c0890c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:26:32.749186Z",
     "iopub.status.busy": "2024-05-01T03:26:32.748808Z",
     "iopub.status.idle": "2024-05-01T03:26:32.753722Z",
     "shell.execute_reply": "2024-05-01T03:26:32.753091Z",
     "shell.execute_reply.started": "2024-05-01T03:26:32.749162Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"seed_word\": \"전세 계약\", \"answer\": [\"전세 계약 기간은 보통 얼마나 되나요?\", \"전세 계약서에는 어떤 내용이 포함되어야 하나요?\", \"전세 계약 시 부동산 중개수수료는 어떻게 책정되나요?\", \"전세 계약 갱신 시 주의해야 할 점은 무엇인가요?\", \"전세 계약 종료 시 보증금 반환은 어떻게 이루어지나요?\", \"전세 계약 중 집주인이 바뀌면 어떻게 해야 하나요?\", \"전세 계약 시 등기부등본은 왜 확인해야 하나요?\", \"전세 계약 기간 중 월세로 전환하는 것이 가능한가요?\", \"전세 계약 시 확인해야 할 집의 하자 사항은 무엇인가요?\", \"전세 계약 분쟁 발생 시 어떤 법적 대응을 할 수 있나요?\"]}\\n',\n",
       " '{\"seed_word\": \"임대차 계약\", \"answer\": [\"임대차 계약서에는 어떤 내용이 포함되어야 하나요?\", \"임대차 계약 기간은 일반적으로 얼마나 되나요?\", \"임대차 계약 시 임차인이 부담해야 하는 비용은 무엇인가요?\", \"임대차 계약 종료 시 임차인의 원상복구 의무는 어떻게 되나요?\", \"임대차 계약 기간 중 임대인이 집을 매도하면 어떻게 되나요?\", \"임대차 계약 갱신 거절 시 임대인이 내세울 수 있는 사유는 무엇인가요?\", \"임대차 계약 시 확인해야 할 특약 사항은 무엇인가요?\", \"임대차 계약 기간 중 임차인이 계약을 해지하고 싶다면 어떻게 해야 하나요?\", \"임대차 계약상 임차인의 권리와 의무는 무엇인가요?\", \"임대차 계약 분쟁 발생 시 어떤 법적 대응을 할 수 있나요?\"]}\\n']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24b29dcf-f85e-48e9-ab0f-dfb1978bf1cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:26:35.267366Z",
     "iopub.status.busy": "2024-05-01T03:26:35.266957Z",
     "iopub.status.idle": "2024-05-01T03:26:35.272861Z",
     "shell.execute_reply": "2024-05-01T03:26:35.272220Z",
     "shell.execute_reply.started": "2024-05-01T03:26:35.267333Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "queries = []\n",
    "for line in query_data:\n",
    "    query = json.loads(line)\n",
    "    queries = queries + query['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e79b1e26-5bc6-48b0-b049-7cb120fe5d07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:26:36.625892Z",
     "iopub.status.busy": "2024-05-01T03:26:36.625416Z",
     "iopub.status.idle": "2024-05-01T03:26:36.633658Z",
     "shell.execute_reply": "2024-05-01T03:26:36.632866Z",
     "shell.execute_reply.started": "2024-05-01T03:26:36.625867Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['전세 계약 기간은 보통 얼마나 되나요?',\n",
       " '전세 계약서에는 어떤 내용이 포함되어야 하나요?',\n",
       " '전세 계약 시 부동산 중개수수료는 어떻게 책정되나요?',\n",
       " '전세 계약 갱신 시 주의해야 할 점은 무엇인가요?',\n",
       " '전세 계약 종료 시 보증금 반환은 어떻게 이루어지나요?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0530fa8b-cc76-4241-8bbb-011d7916053f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:26:37.633940Z",
     "iopub.status.busy": "2024-05-01T03:26:37.633284Z",
     "iopub.status.idle": "2024-05-01T03:26:37.640719Z",
     "shell.execute_reply": "2024-05-01T03:26:37.640028Z",
     "shell.execute_reply.started": "2024-05-01T03:26:37.633891Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da64bd8-30be-4fff-bd61-76cb89867d54",
   "metadata": {},
   "source": [
    "selenium으로 네이버 검색 데이터를 수집할 때, webdriver의 버전을 확인하세요.  \n",
    "버전에 맞는 webdriver 설치 방법은 [여기](https://wikidocs.net/91474)를 참조하세요.  \n",
    "본 문서의 selenium 코드는 [wikidocs](https://wikidocs.net/137914) 내용을 참조하였습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63e1ba1f-2e06-481d-a66b-6ad9e99b0940",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:26:42.192188Z",
     "iopub.status.busy": "2024-05-01T03:26:42.191571Z",
     "iopub.status.idle": "2024-05-01T06:15:40.580101Z",
     "shell.execute_reply": "2024-05-01T06:15:40.579579Z",
     "shell.execute_reply.started": "2024-05-01T03:26:42.192145Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 960/960 [2:48:52<00:00, 10.55s/it]\n"
     ]
    }
   ],
   "source": [
    "search_data = utils.get_document_through_selenium(inputs=queries, save_path = \"./data/document.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba1dc97c-e57d-4930-9e9f-764a77521247",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T06:15:40.581282Z",
     "iopub.status.busy": "2024-05-01T06:15:40.581138Z",
     "iopub.status.idle": "2024-05-01T06:15:40.595623Z",
     "shell.execute_reply": "2024-05-01T06:15:40.595365Z",
     "shell.execute_reply.started": "2024-05-01T06:15:40.581270Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "말해야 되나요? 주택임대차보호법 제 6조 제 1항 (계약의 갱신) 계약이 해지되기 6개월 전부터 2개월 전까지, 계약을 해지하겠다는 통보를 해야 한다. 즉, 법률상 늦어도 계약이 종료되기 2개월 전까지는 임대인에게 말해야 된다는 뜻인데요. 만약 해당 기간 안에 말하지 않았다면? 자동으로 연장되는 묵시적 갱신이 될 수 있습니다. 때문에, 종료 시점에 맞춰서 자금을...\n"
     ]
    }
   ],
   "source": [
    "print(utils.jload(\"./data/document.json\")[0]['document'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6130e7-344c-4058-ace3-39eb80087cfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-28T07:05:34.818904Z",
     "iopub.status.busy": "2024-04-28T07:05:34.818806Z",
     "iopub.status.idle": "2024-04-28T07:05:34.820806Z",
     "shell.execute_reply": "2024-04-28T07:05:34.820406Z",
     "shell.execute_reply.started": "2024-04-28T07:05:34.818896Z"
    },
    "tags": []
   },
   "source": [
    "### 5. encoder 모델을 활용하여 데이터를 유사도 기준으로 정렬하기\n",
    "최근에 공개된 intfloat의 e5 Multi Lingual 모델을 사용하여 유사도를 계산합니다.  \n",
    "질문을 했을 때, 검색되는 인기글 데이터들중 유사도가 높은 순서대로 문서를 다시 정렬합니다.  \n",
    "정렬된 순서대로 데이터를 좀더 많이 참조하도록 프롬프트를 통해 지시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6716c4ee-7092-4b5b-9090-7e3c6c20e683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T06:15:40.596163Z",
     "iopub.status.busy": "2024-05-01T06:15:40.596081Z",
     "iopub.status.idle": "2024-05-01T06:15:40.611240Z",
     "shell.execute_reply": "2024-05-01T06:15:40.610687Z",
     "shell.execute_reply.started": "2024-05-01T06:15:40.596154Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_data = utils.jload(\"./data/document.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6c1f6f-cd6c-4b89-a0ee-ff728c8e9ca6",
   "metadata": {},
   "source": [
    "e5모델의 자세한 내용은 [hugginface](https://huggingface.co/intfloat/e5-base-v2)를 참조하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37a42296-087f-41be-b539-d2a5219a6ac0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T06:15:40.614003Z",
     "iopub.status.busy": "2024-05-01T06:15:40.613661Z",
     "iopub.status.idle": "2024-05-01T06:19:13.954314Z",
     "shell.execute_reply": "2024-05-01T06:19:13.953569Z",
     "shell.execute_reply.started": "2024-05-01T06:15:40.613986Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▏                                                       | 299/960 [03:31<07:48,  1.41it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m tqdm(search_data):\n\u001b[1;32m      7\u001b[0m     input1 \u001b[38;5;241m=\u001b[39m similarity\u001b[38;5;241m.\u001b[39maverage_pool(model\u001b[38;5;241m=\u001b[39mmodel, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, input_text\u001b[38;5;241m=\u001b[39mquestion[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m     input2 \u001b[38;5;241m=\u001b[39m \u001b[41msimilarity\u001b[49m\u001b[38;5;241;41m.\u001b[39;49m\u001b[41maverage_pool\u001b[49m\u001b[41m(\u001b[49m\u001b[41mmodel\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mmodel\u001b[49m\u001b[41m,\u001b[49m\u001b[41m \u001b[49m\u001b[41mtokenizer\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mtokenizer\u001b[49m\u001b[41m,\u001b[49m\u001b[41m \u001b[49m\u001b[41minput_text\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mquestion\u001b[49m\u001b[41m[\u001b[49m\u001b[38;5;124;41m'\u001b[39;49m\u001b[38;5;124;41mdocument\u001b[39;49m\u001b[38;5;124;41m'\u001b[39;49m\u001b[41m]\u001b[49m\u001b[41m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     scores \u001b[38;5;241m=\u001b[39m similarity\u001b[38;5;241m.\u001b[39mcosine_similarity(input1, input2)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# scores 순서대로 정렬\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/study/project/instruction-tuning-with-rag-example/similarity.py:25\u001b[0m, in \u001b[0;36maverage_pool\u001b[0;34m(model, tokenizer, input_text)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maverage_pool\u001b[39m(\n\u001b[1;32m     10\u001b[0m         model: transformers\u001b[38;5;241m.\u001b[39mPreTrainedModel,\n\u001b[1;32m     11\u001b[0m         tokenizer: transformers\u001b[38;5;241m.\u001b[39mPreTrainedTokenizer,\n\u001b[1;32m     12\u001b[0m         input_text: Union[List[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mstr\u001b[39m]\n\u001b[1;32m     13\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     14\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sequence의 Average Pool로 Embedding 값을 계산합니다.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[41mtokenizer\u001b[49m\u001b[41m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[41m        \u001b[49m\u001b[41minput_text\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[41m        \u001b[49m\u001b[41mmax_length\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mtokenizer\u001b[49m\u001b[38;5;241;41m.\u001b[39;49m\u001b[41mmodel_max_length\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[41m        \u001b[49m\u001b[41mpadding\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[38;5;28;41;01mTrue\u001b[39;49;00m\u001b[41m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[41m        \u001b[49m\u001b[41mtruncation\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[38;5;28;41;01mTrue\u001b[39;49;00m\u001b[41m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[41m        \u001b[49m\u001b[41mreturn_tensors\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[38;5;124;41m\"\u001b[39;49m\u001b[38;5;124;41mpt\u001b[39;49m\u001b[38;5;124;41m\"\u001b[39;49m\n\u001b[1;32m     31\u001b[0m \u001b[41m    \u001b[49m\u001b[41m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     33\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m     34\u001b[0m     last_hidden \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mlast_hidden_state\u001b[38;5;241m.\u001b[39mmasked_fill(\u001b[38;5;241m~\u001b[39minputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]\u001b[38;5;241m.\u001b[39mbool(), \u001b[38;5;241m0.0\u001b[39m)\n",
      "File \u001b[0;32m~/python_env/.base/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2872\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2870\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2871\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2872\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;41mself\u001b[39;49m\u001b[38;5;241;41m.\u001b[39;49m\u001b[41m_call_one\u001b[49m\u001b[41m(\u001b[49m\u001b[41mtext\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mtext\u001b[49m\u001b[41m,\u001b[49m\u001b[41m \u001b[49m\u001b[41mtext_pair\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mtext_pair\u001b[49m\u001b[41m,\u001b[49m\u001b[41m \u001b[49m\u001b[38;5;241;41m*\u001b[39;49m\u001b[38;5;241;41m*\u001b[39;49m\u001b[41mall_kwargs\u001b[49m\u001b[41m)\u001b[49m\n\u001b[1;32m   2873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2874\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/python_env/.base/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2958\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2954\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2955\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2956\u001b[0m         )\n\u001b[1;32m   2957\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 2958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;41mself\u001b[39;49m\u001b[38;5;241;41m.\u001b[39;49m\u001b[41mbatch_encode_plus\u001b[49m\u001b[41m(\u001b[49m\n\u001b[1;32m   2959\u001b[0m \u001b[41m        \u001b[49m\u001b[41mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mbatch_text_or_text_pairs\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   2960\u001b[0m \u001b[41m        \u001b[49m\u001b[41madd_special_tokens\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41madd_special_tokens\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   2961\u001b[0m \u001b[41m        \u001b[49m\u001b[41mpadding\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mpadding\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   2962\u001b[0m \u001b[41m        \u001b[49m\u001b[41mtruncation\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mtruncation\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   2963\u001b[0m \u001b[41m        \u001b[49m\u001b[41mmax_length\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mmax_length\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   2964\u001b[0m \u001b[41m        \u001b[49m\u001b[41mstride\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mstride\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   2965\u001b[0m \u001b[41m        \u001b[49m\u001b[41mis_split_into_words\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mis_split_into_words\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   2966\u001b[0m \u001b[41m        \u001b[49m\u001b[41mpad_to_multiple_of\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mpad_to_multiple_of\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   2967\u001b[0m \u001b[41m        \u001b[49m\u001b[41mreturn_tensors\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mreturn_tensors\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   2968\u001b[0m \u001b[41m        \u001b[49m\u001b[41mreturn_token_type_ids\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mreturn_token_type_ids\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   2969\u001b[0m \u001b[41m        \u001b[49m\u001b[41mreturn_attention_mask\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mreturn_attention_mask\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   2970\u001b[0m \u001b[41m        \u001b[49m\u001b[41mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mreturn_overflowing_tokens\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   2971\u001b[0m \u001b[41m        \u001b[49m\u001b[41mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mreturn_special_tokens_mask\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   2972\u001b[0m \u001b[41m        \u001b[49m\u001b[41mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mreturn_offsets_mapping\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   2973\u001b[0m \u001b[41m        \u001b[49m\u001b[41mreturn_length\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mreturn_length\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   2974\u001b[0m \u001b[41m        \u001b[49m\u001b[41mverbose\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mverbose\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   2975\u001b[0m \u001b[41m        \u001b[49m\u001b[38;5;241;41m*\u001b[39;49m\u001b[38;5;241;41m*\u001b[39;49m\u001b[41mkwargs\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   2976\u001b[0m \u001b[41m    \u001b[49m\u001b[41m)\u001b[49m\n\u001b[1;32m   2977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   2979\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   2980\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2996\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2997\u001b[0m     )\n",
      "File \u001b[0;32m~/python_env/.base/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3149\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3139\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3140\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3141\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3142\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3146\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3147\u001b[0m )\n\u001b[0;32m-> 3149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;41mself\u001b[39;49m\u001b[38;5;241;41m.\u001b[39;49m\u001b[41m_batch_encode_plus\u001b[49m\u001b[41m(\u001b[49m\n\u001b[1;32m   3150\u001b[0m \u001b[41m    \u001b[49m\u001b[41mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mbatch_text_or_text_pairs\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   3151\u001b[0m \u001b[41m    \u001b[49m\u001b[41madd_special_tokens\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41madd_special_tokens\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   3152\u001b[0m \u001b[41m    \u001b[49m\u001b[41mpadding_strategy\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mpadding_strategy\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   3153\u001b[0m \u001b[41m    \u001b[49m\u001b[41mtruncation_strategy\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mtruncation_strategy\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   3154\u001b[0m \u001b[41m    \u001b[49m\u001b[41mmax_length\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mmax_length\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   3155\u001b[0m \u001b[41m    \u001b[49m\u001b[41mstride\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mstride\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   3156\u001b[0m \u001b[41m    \u001b[49m\u001b[41mis_split_into_words\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mis_split_into_words\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   3157\u001b[0m \u001b[41m    \u001b[49m\u001b[41mpad_to_multiple_of\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mpad_to_multiple_of\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   3158\u001b[0m \u001b[41m    \u001b[49m\u001b[41mreturn_tensors\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mreturn_tensors\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   3159\u001b[0m \u001b[41m    \u001b[49m\u001b[41mreturn_token_type_ids\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mreturn_token_type_ids\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   3160\u001b[0m \u001b[41m    \u001b[49m\u001b[41mreturn_attention_mask\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mreturn_attention_mask\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   3161\u001b[0m \u001b[41m    \u001b[49m\u001b[41mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mreturn_overflowing_tokens\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   3162\u001b[0m \u001b[41m    \u001b[49m\u001b[41mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mreturn_special_tokens_mask\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   3163\u001b[0m \u001b[41m    \u001b[49m\u001b[41mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mreturn_offsets_mapping\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   3164\u001b[0m \u001b[41m    \u001b[49m\u001b[41mreturn_length\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mreturn_length\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   3165\u001b[0m \u001b[41m    \u001b[49m\u001b[41mverbose\u001b[49m\u001b[38;5;241;41m=\u001b[39;49m\u001b[41mverbose\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   3166\u001b[0m \u001b[41m    \u001b[49m\u001b[38;5;241;41m*\u001b[39;49m\u001b[38;5;241;41m*\u001b[39;49m\u001b[41mkwargs\u001b[49m\u001b[41m,\u001b[49m\n\u001b[1;32m   3167\u001b[0m \u001b[41m\u001b[49m\u001b[41m)\u001b[49m\n",
      "File \u001b[0;32m~/python_env/.base/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:537\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;66;03m# Convert the output to have dict[list] from list[dict] and remove the additional overflows dimension\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;66;03m# From (variable) shape (batch, overflows, sequence length) to ~ (batch * overflows, sequence length)\u001b[39;00m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# (we say ~ because the number of overflow varies with the example in the batch)\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# To match each overflowing sample with the original sample in the batch\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# we add an overflow_to_sample_mapping array (see below)\u001b[39;00m\n\u001b[1;32m    536\u001b[0m sanitized_tokens \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 537\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[41mtokens_and_encodings\u001b[49m\u001b[41m[\u001b[49m\u001b[38;5;241;41m0\u001b[39;49m\u001b[41m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    538\u001b[0m     stack \u001b[38;5;241m=\u001b[39m [e \u001b[38;5;28;01mfor\u001b[39;00m item, _ \u001b[38;5;129;01min\u001b[39;00m tokens_and_encodings \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m item[key]]\n\u001b[1;32m    539\u001b[0m     sanitized_tokens[key] \u001b[38;5;241m=\u001b[39m stack\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "model_id = \"intfloat/e5-base-v2\"\n",
    "model_device = \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, device_map=model_device)\n",
    "model = AutoModel.from_pretrained(model_id)\n",
    "\n",
    "for question in tqdm(search_data):\n",
    "    input1 = similarity.average_pool(model=model, tokenizer=tokenizer, input_text=question['question'])\n",
    "    input2 = similarity.average_pool(model=model, tokenizer=tokenizer, input_text=question['document'])\n",
    "    scores = similarity.cosine_similarity(input1, input2)\n",
    "    \n",
    "    # scores 순서대로 정렬\n",
    "    question['document'], question['scores'] = similarity.sort_by_iterable(target=question['document'], key_iter=scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaf1c9d-4c3b-4efc-903c-fed86027077f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-01T06:19:13.954646Z",
     "iopub.status.idle": "2024-05-01T06:19:13.954751Z",
     "shell.execute_reply": "2024-05-01T06:19:13.954697Z",
     "shell.execute_reply.started": "2024-05-01T06:19:13.954692Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "utils.jsave(search_data, \"./data/search_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26fe065-19a8-4e0a-9288-d5bfcf4a198e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 6. Instuction 데이터셋 만들기\n",
    "완성된 질문리스트와 인기글 데이터를 통해 ChatGPT에 정답을 출력하도록 요청합니다.  \n",
    "ChatGPT는 아래의 프롬프트처럼 question에 대한 answer 답변을 출력합니다.  \n",
    "완성된 question, answer 텍스트는 학습시킬 모델의 훈련용 데이터셋으로 전달됩니다.  \n",
    "본 문서의 프롬프트는 [Stanford Alpaca의 프롬프트](https://github.com/tatsu-lab/stanford_alpaca/blob/main/prompt.txthttps://github.com/tatsu-lab/stanford_alpaca/blob/main/prompt.txt)를 참조하였습니다.  \n",
    "예시 데이터는 `instruction.jsonl`로 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71a94b5-435c-402f-906c-44b844c8989c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-01T06:19:13.955107Z",
     "iopub.status.idle": "2024-05-01T06:19:13.955266Z",
     "shell.execute_reply": "2024-05-01T06:19:13.955203Z",
     "shell.execute_reply.started": "2024-05-01T06:19:13.955198Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(prompts.INSTRUCTION_PROMPT_PREFIX + prompts.INSTRUCTION_PROMPT_CONTENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a00105-8d72-46d6-b762-afc2c90388d3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-01T06:19:13.955541Z",
     "iopub.status.idle": "2024-05-01T06:19:13.955638Z",
     "shell.execute_reply": "2024-05-01T06:19:13.955583Z",
     "shell.execute_reply.started": "2024-05-01T06:19:13.955579Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "search = utils.jload(\"./data/search_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f88e377-cddf-4d41-beda-34d13b58f96c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-01T06:19:13.955909Z",
     "iopub.status.idle": "2024-05-01T06:19:13.956013Z",
     "shell.execute_reply": "2024-05-01T06:19:13.955958Z",
     "shell.execute_reply.started": "2024-05-01T06:19:13.955953Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 리스트 형태인 document 데이터를 하나로 합치기\n",
    "for data in search:\n",
    "    data['document'] = \"\\n\".join([f\"{idx+1}. {d}\" for idx, d in enumerate(data['document'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e47d259-3bd7-4241-adfe-a37da70e23b8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-01T06:19:13.956310Z",
     "iopub.status.idle": "2024-05-01T06:19:13.956404Z",
     "shell.execute_reply": "2024-05-01T06:19:13.956353Z",
     "shell.execute_reply.started": "2024-05-01T06:19:13.956349Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(search[0]['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455bfdac-8ad1-41cf-85be-54fbbdf26e13",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-01T06:19:13.956752Z",
     "iopub.status.idle": "2024-05-01T06:19:13.956847Z",
     "shell.execute_reply": "2024-05-01T06:19:13.956795Z",
     "shell.execute_reply.started": "2024-05-01T06:19:13.956791Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(prompts.INSTRUCTION_PROMPT_CONTENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d6649-9f4a-454a-b9b5-78b4751f9dd8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-01T06:19:13.957169Z",
     "iopub.status.idle": "2024-05-01T06:19:13.957262Z",
     "shell.execute_reply": "2024-05-01T06:19:13.957212Z",
     "shell.execute_reply.started": "2024-05-01T06:19:13.957207Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = prompts.INSTRUCTION_PROMPT_PREFIX\n",
    "instructions = []\n",
    "total_instructions = len(search) // 10\n",
    "for index in range(1, total_instructions + 2):\n",
    "    start_index = (index - 1) * 10\n",
    "    end_index = index * 10\n",
    "    content = \"\\n\".join([\n",
    "        prompts.INSTRUCTION_PROMPT_CONTENT.format(question = data['question'], document = data['document'])\n",
    "        for data in search[start_index:end_index]\n",
    "    ])\n",
    "    instruction = prefix + content\n",
    "    instructions.append(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f8f046-7f46-407b-83a4-e1a6f837d372",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-01T06:19:13.957530Z",
     "iopub.status.idle": "2024-05-01T06:19:13.957613Z",
     "shell.execute_reply": "2024-05-01T06:19:13.957573Z",
     "shell.execute_reply.started": "2024-05-01T06:19:13.957569Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(instructions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9db1a4-759b-462a-83b4-0645ad4ceaf4",
   "metadata": {},
   "source": [
    "포맷팅하여 완성한 프롬프트는 아래와 같습니다.  \n",
    "아래 데이터를 ChatGPT API로 넘겨줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4d6657-68fe-408a-8951-656ec3288cce",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-01T06:19:13.957845Z",
     "iopub.status.idle": "2024-05-01T06:19:13.957932Z",
     "shell.execute_reply": "2024-05-01T06:19:13.957884Z",
     "shell.execute_reply.started": "2024-05-01T06:19:13.957880Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(instructions[0][:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b33665-0ece-4d79-898a-a05ff6880f0c",
   "metadata": {},
   "source": [
    "`gpt-4-turbo`는 `gpt-4` 보다 성능이 좋으면서 가격은 1/3입니다.  \n",
    "`gpt-4-turbo`를 사용하길 추천드립니다.  \n",
    "[OpenAI 가격 정책](https://openai.com/pricing)을 참조하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6838a02f-2375-4fef-9817-b856e3f1658b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T02:00:45.568410Z",
     "iopub.status.busy": "2024-04-29T02:00:45.567626Z",
     "iopub.status.idle": "2024-04-29T02:00:45.577575Z",
     "shell.execute_reply": "2024-04-29T02:00:45.576075Z",
     "shell.execute_reply.started": "2024-04-29T02:00:45.568355Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for inst in tqdm(instructions):\n",
    "    result = utils.get_completion(inst, model=\"gpt-4-turbo-2024-04-09\")\n",
    "    with open(\"instruction.jsonl\", \"a\", encoding=\"utf-8\") as f:\n",
    "        for line in result.split(\"\\n\"):\n",
    "            f.write(line)\n",
    "            f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
